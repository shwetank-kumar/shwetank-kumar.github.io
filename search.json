[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash\n\n\n\n\n\n\nrecommenders\n\n\ncode\n\n\n\n\n\n\n\n\n\nAug 24, 2024\n\n\nShwetank Kumar\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "favorite-eggheads.html",
    "href": "favorite-eggheads.html",
    "title": "Shwetank Kumar",
    "section": "",
    "text": "AI tutorials - Andrej Karpathy\nPublic company valuations - Ashwath Damodaran\nFinancial systems - Patrick McKenzie"
  },
  {
    "objectID": "favorite-eggheads.html#favorite-topics-and-experts",
    "href": "favorite-eggheads.html#favorite-topics-and-experts",
    "title": "Shwetank Kumar",
    "section": "",
    "text": "AI tutorials - Andrej Karpathy\nPublic company valuations - Ashwath Damodaran\nFinancial systems - Patrick McKenzie"
  },
  {
    "objectID": "posts/cold-start/index.html",
    "href": "posts/cold-start/index.html",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "",
    "text": "Hey there fellow data scientists! Grab a cup of your favorite caffeinated beverage (I’m on my third espresso as I write this), and let’s dive into the world of recommendation systems. But not just any recommendation systems - we’re talking about bootstrapping a brand recommender from absolutely nothing to a money-printing machine. Buckle up, because this is going to be a wild ride through the land of data, algorithms, and unexpectedly delightful customer experiences."
  },
  {
    "objectID": "posts/cold-start/index.html#the-problem-e-commerce-is-a-jungle-and-your-customers-are-lost",
    "href": "posts/cold-start/index.html#the-problem-e-commerce-is-a-jungle-and-your-customers-are-lost",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "The Problem: E-commerce Is a Jungle (And Your Customers Are Lost)",
    "text": "The Problem: E-commerce Is a Jungle (And Your Customers Are Lost)\nPicture this: You’ve just launched your e-commerce platform. It’s beautiful, it’s fast, and it’s got more brands than you can shake a stick at. You’re feeling pretty good about yourself. But then reality hits you like a ton of bricks wrapped in user feedback forms:\n“I can’t find anything I like!” “There are too many options!” “Why are you showing me diving equipment? I live in a desert!” “I just bought shoes! Why are you showing me more shoes!”\nSound familiar? If it doesn’t yet, trust me, it will. You see, in the world of e-commerce, choice is both a blessing and a curse. Too little choice, and customers feel constrained. Too much choice, and they feel overwhelmed. It’s like being a kid in a candy store, except the candy store is the size of a Walmart, and the kid has analysis paralysis.\nThis, my friends, is where a good recommendation system comes in. It’s like having a wise, all-knowing friend who gently guides your customers to their next favorite purchase. And today, we’re going to build that friend from scratch."
  },
  {
    "objectID": "posts/cold-start/index.html#step-0-the-oh-crap-we-have-no-data-phase",
    "href": "posts/cold-start/index.html#step-0-the-oh-crap-we-have-no-data-phase",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "Step 0: The “Oh Crap, We Have No Data” Phase",
    "text": "Step 0: The “Oh Crap, We Have No Data” Phase\nLet’s start at the very beginning (a very good place to start, as Julie Andrews would say). You’ve just launched your platform, and your data cupboard is as bare as Old Mother Hubbard’s. What do you do?\nWell, first, take a deep breath. Now, repeat after me: “Random is better than nothing.”\nYou see, when you have no data, your best friend is Mr. Random. It’s not ideal, but it’s a start. And in the world of startups, starting is half the battle.\nLet’s whip up a quick Python function to generate random recommendations:\nimport random\n\ndef get_random_recommendations(all_brands, n=5):\n    return random.sample(all_brands, min(n, len(all_brands)))\n\n# Example usage\nall_brands = [\"Nike\", \"Adidas\", \"Puma\", \"Reebok\", \"Under Armour\", \"New Balance\", \"Asics\", \"Converse\", \"Vans\", \"Skechers\"]\nprint(get_random_recommendations(all_brands))\nNow, I know what you’re thinking. “But dude! This is just throwing darts blindfolded! How is this helping anyone?” Two things - 1) That’s Dr. Mr. Dude! Dude is my 8 year old. 2) And you’re right, it’s not ideal. But here’s the secret: it’s not about being perfect; it’s about starting the flywheel.\nEvery time a user sees a random recommendation, you’re gathering data. Maybe they ignore it (data point!). Maybe they click on it (data point!). Maybe they buy it (cha-ching and data point!). Every interaction is a breadcrumb that will lead you out of the data desert.\nPro tip: While you’re showing random recommendations, make sure you’re logging EVERYTHING. Every view, every click, every purchase. This data will be worth its weight in gold later on. Trust me, future you will thank present you for this foresight. And while you are at it do make sure that the data is high quality. Algorithms are fickle and state of the art on those changes every week – nay day! But poor quality data once logged sets the ceiling on what you can do."
  },
  {
    "objectID": "posts/cold-start/index.html#step-1-the-we-have-some-data-but-its-not-about-users-phase",
    "href": "posts/cold-start/index.html#step-1-the-we-have-some-data-but-its-not-about-users-phase",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "Step 1: The “We Have Some Data, But It’s Not About Users” Phase",
    "text": "Step 1: The “We Have Some Data, But It’s Not About Users” Phase\nAlright, so you’ve been running your random recommendation engine for a while. You’ve got some sales, you’ve got some brand data, but you still don’t have enough user interaction data to build a proper collaborative filtering system. Don’t worry, we’re going to make lemonade out of these lemons.\nEnter: Feature-Based Clustering.\nNow, gather ’round, because I’m about to share a secret that took me embarrassingly long to figure out: brands, like people, have personalities. And just like you wouldn’t set up your quiet, bookish friend with your party-animal cousin (trust me, I’ve made that mistake), you shouldn’t be recommending wildly dissimilar brands to your users.\nLet’s create a simple example using K-means clustering. Don’t let the fancy name scare you - it’s just a way of grouping similar things together.\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\n# Example brand features (price, target_age, sportiness)\nbrand_features = {\n    \"Nike\": [80, 25, 9],\n    \"Adidas\": [75, 30, 8],\n    \"Puma\": [60, 28, 7],\n    \"Reebok\": [65, 35, 6],\n    \"Under Armour\": [70, 27, 9],\n    \"New Balance\": [85, 40, 5],\n    \"Asics\": [90, 35, 8],\n    \"Converse\": [55, 22, 3],\n    \"Vans\": [50, 20, 2],\n    \"Skechers\": [45, 45, 4]\n}\n\ndef cluster_brands(brand_features, n_clusters=3):\n    brands = list(brand_features.keys())\n    features = np.array(list(brand_features.values()))\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    clusters = kmeans.fit_predict(features)\n    \n    brand_clusters = {brand: cluster for brand, cluster in zip(brands, clusters)}\n    return brand_clusters\n\nbrand_clusters = cluster_brands(brand_features)\nprint(brand_clusters)\n\ndef get_cluster_recommendations(purchased_brand, brand_clusters, n=5):\n    cluster = brand_clusters[purchased_brand]\n    cluster_brands = [brand for brand, c in brand_clusters.items() if c == cluster]\n    return random.sample(cluster_brands, min(n, len(cluster_brands)))\n\n# Example usage\npurchased_brand = \"Nike\"\nprint(get_cluster_recommendations(purchased_brand, brand_clusters))\n\nStory 1\n[Now, let me tell you a story. I once worked with a client who sold both high-end designer shoes and budget-friendly sneakers. They were using a random recommendation engine, and you know what happened? They were recommending $1000 Italian leather loafers to college students looking for $30 canvas sneakers. Their bounce rate was through the roof, and their conversion rate was lower than my undergrad GPA.]\nWe implemented this simple clustering system, and boom! Conversion rates jumped by … umm I am under NDA so cant quote the exact number … but lets say XXXX basis points almost overnight. Why? Because we were no longer trying to sell apples to orange lovers. We were showing people more of what they already liked.\n\n\nStory 2\nNow, let me share an interesting case study that illustrates the power of this approach. Back in 2015, Etsy, the e-commerce website focused on handmade or vintage items, faced a challenge similar to our hypothetical scenario. They had a vast array of products, from $5 handmade bracelets to $500 vintage furniture pieces. Initially, their recommendation system was quite basic, often suggesting items that were wildly different in style and price point from what a user was viewing. This led to a poor user experience and missed sales opportunities. Etsy’s data science team implemented a more sophisticated system that clustered items based on various features like price, category, style, and even color palette. The result? According to their engineering blog, they saw a significant increase in click-through rates on recommended items and a boost in overall sales. This just goes to show that even a relatively simple clustering approach can have a dramatic impact on your recommendation quality and, ultimately, your bottom line.\nBut here’s the kicker: we were still maintaining an element of randomness within each cluster. This is crucial because it allows you to continue exploring the possibility space. You’re not just preaching to the choir; you’re introducing the choir to new hymns they might enjoy."
  },
  {
    "objectID": "posts/cold-start/index.html#step-2-the-now-were-cooking-with-gas-phase",
    "href": "posts/cold-start/index.html#step-2-the-now-were-cooking-with-gas-phase",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "Step 2: The “Now We’re Cooking with Gas” Phase",
    "text": "Step 2: The “Now We’re Cooking with Gas” Phase\nAlright, my data-hungry friends, we’ve arrived at the juicy part. You’ve been diligently collecting user interaction data (you have, haven’t you?), and now it’s time to put it to use. We’re going to build a purchase-based association model.\nThis is where the magic really starts to happen. We’re going to create a system that understands that people who buy brand A often buy brand B, even if we don’t know why. It’s like being a really good matchmaker without understanding the intricacies of human psychology.\nLet’s cook up a simple association model:\nfrom collections import defaultdict\n\ndef build_association_model(purchase_data):\n    associations = defaultdict(lambda: defaultdict(int))\n    for purchase in purchase_data:\n        for i, brand1 in enumerate(purchase):\n            for brand2 in purchase[i+1:]:\n                associations[brand1][brand2] += 1\n                associations[brand2][brand1] += 1\n    return associations\n\n# Example purchase data\npurchase_data = [\n    [\"Nike\", \"Adidas\"],\n    [\"Nike\", \"Under Armour\"],\n    [\"Adidas\", \"Puma\"],\n    [\"Puma\", \"Reebok\"],\n    [\"Nike\", \"Converse\"],\n    [\"Vans\", \"Converse\"],\n    [\"New Balance\", \"Asics\"],\n    [\"Skechers\", \"New Balance\"]\n]\n\nassociation_model = build_association_model(purchase_data)\n\ndef get_associated_brands(brand, association_model, n=5):\n    associated = sorted(association_model[brand].items(), key=lambda x: x[1], reverse=True)\n    return [b for b, _ in associated[:n]]\n\n# Example usage\npurchased_brand = \"Nike\"\nprint(get_associated_brands(purchased_brand, association_model))\n\nStory 1\nNow, let me tell you why this is a game-changer. Sometime back, I was consulting for a mid-sized fashion retailer. They were struggling to cross-sell effectively. Their method was to have their merchandisers manually create “outfits” and recommend items based on those.\nIt was a nightmare. It didn’t scale, it was biased towards the merchandisers’ personal tastes, and it completely missed unexpected associations.\nWe implemented a system similar to this, and do you know what we found? People who bought red sneakers often bought black hoodies. Why? We had no idea. But it worked. Cross-sell revenue increased by 23% in the first month.\n\n\nStory 2\nNow, let me tell you why this is a game-changer. Consider the case of Amazon, the e-commerce giant. In their early days, they primarily sold books. But as they expanded into other product categories, they faced a massive challenge: how to effectively cross-sell across these diverse categories? Their solution was to implement a sophisticated association model, much like the one we’ve just built (though admittedly, theirs was far more complex). This “item-to-item collaborative filtering” approach, as they called it, allowed them to say, “Customers who bought this item also bought…” The impact was staggering. According to a paper published by Amazon’s engineers, this recommendation system was responsible for 35% of their sales (as of 2013). That’s the power of understanding and leveraging purchase associations. But here’s where it gets really interesting. We’re not just creating direct associations. Oh no, we’re going to take this to the next level with transitive associations.\nBut here’s where it gets really interesting. We’re not just creating direct associations. Oh no, we’re going to take this to the next level with transitive associations."
  },
  {
    "objectID": "posts/cold-start/index.html#step-3-the-six-degrees-of-kevin-bacon-phase",
    "href": "posts/cold-start/index.html#step-3-the-six-degrees-of-kevin-bacon-phase",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "Step 3: The “Six Degrees of Kevin Bacon” Phase",
    "text": "Step 3: The “Six Degrees of Kevin Bacon” Phase\nAlright, pop culture reference time. Have you ever played “Six Degrees of Kevin Bacon”? The game where you try to connect any actor to Kevin Bacon through no more than six movie connections? Well, we’re going to do something similar with our brands.\nYou see, direct associations are great, but they’re limited. What if we could create a web of associations, where brand A is connected to brand B, which is connected to brand C, creating an indirect connection between A and C?\nThis is where transitive associations come in. It’s like being at a party and having your friend introduce you to their friend, who then introduces you to their friend. Suddenly, your network has exploded.\nLet’s enhance our association model:\ndef build_transitive_associations(direct_associations, depth=2):\n    transitive = defaultdict(lambda: defaultdict(int))\n    \n    for brand in direct_associations:\n        queue = [(brand, 0)]\n        visited = set()\n        \n        while queue:\n            current, level = queue.pop(0)\n            if level &gt; depth:\n                break\n            \n            if current in visited:\n                continue\n            visited.add(current)\n            \n            for associated, strength in direct_associations[current].items():\n                transitive[brand][associated] += strength / (2 ** level)\n                if associated not in visited:\n                    queue.append((associated, level + 1))\n    \n    return transitive\n\ntransitive_associations = build_transitive_associations(association_model)\n\ndef get_transitive_recommendations(brand, transitive_associations, n=5):\n    associated = sorted(transitive_associations[brand].items(), key=lambda x: x[1], reverse=True)\n    return [b for b, _ in associated[:n] if b != brand]\n\n# Example usage\npurchased_brand = \"Nike\"\nprint(get_transitive_recommendations(purchased_brand, transitive_associations))\nNow, let me tell you why this is so powerful. I once worked with a niche bookstore. They specialized in obscure academic texts. The problem was, their inventory was so specific that direct associations were rare. A customer might buy a book on “The Mating Habits of 12th Century Mongolian Horses” (I’m not making this up), but how many other people are going to buy that exact book?\nWe implemented transitive associations, and suddenly, magic happened. We could recommend “The Economic Impact of Horse Trading in Medieval Asia” to someone who bought the Mongolian horse book, even if no one had ever bought these two books together. Why? Because there was a chain of associations linking them.\nThe result? A 40% increase in average order value. Turns out, academics love going down rabbit holes. Who knew?"
  },
  {
    "objectID": "posts/cold-start/index.html#step-4-the-decision-tree-but-make-it-fashionable-phase",
    "href": "posts/cold-start/index.html#step-4-the-decision-tree-but-make-it-fashionable-phase",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "Step 4: The “Decision Tree, But Make It Fashionable” Phase",
    "text": "Step 4: The “Decision Tree, But Make It Fashionable” Phase\nAlright, we’re in the endgame now. We’ve got our associations, we’ve got our transitive relationships, but we’re still missing something. We need a way to create diverse, interesting recommendation paths. Enter: The Recommendation Tree.\nThink of this as a decision tree, but instead of decisions, we’re making recommendations. It’s like those “Choose Your Own Adventure” books, but for shopping. And let me tell you, customers love an adventure.\nLet’s build our tree:\nclass BrandNode:\n    def __init__(self, brand):\n        self.brand = brand\n        self.children = []\n\ndef build_recommendation_tree(associations, root_brand, depth=3):\n    if depth == 0:\n        return None\n    \n    root = BrandNode(root_brand)\n    associated = sorted(associations[root_brand].items(), key=lambda x: x[1], reverse=True)\n    \n    for brand, _ in associated[:3]:  # Limit to top 3 associations for simplicity\n        child = build_recommendation_tree(associations, brand, depth-1)\n        if child:\n            root.children.append(child)\n    \n    return root\n\ndef traverse_tree(root, path=None):\n    if path is None:\n        path = []\n    \n    path.append(root.brand)\n    yield path\n    \n    for child in root.children:\n        yield from traverse_tree(child, path.copy())\n\n# Build and traverse the tree\nroot_brand = \"Nike\"\nrec_tree = build_recommendation_tree(transitive_associations, root_brand)\n\nprint(\"Recommendation paths:\")\nfor path in traverse_tree(rec_tree):\n    print(\" -&gt; \".join(path))\nNow, why is this tree structure so powerful? Let me tell you a tale of two customers.\nCustomer A comes to your site and buys a pair of Nike sneakers. You recommend Adidas (because they’re often bought together). They’re not interested. In a simple system, you might be stuck. But with our tree, you can pivot. You might go Nike -&gt; Under Armour -&gt; Puma. Suddenly, you’ve opened up a new branch of possibilities.\nCustomer B also buys Nike, but they’re more adventurous. They follow the path Nike -&gt; Adidas -&gt; Puma -&gt; Reebok. Each step is a new discovery, each purchase reinforcing their trust in your recommendations.\nI implemented a system like this for a large outdoor equipment retailer. The result? A 30% increase in customer lifetime value. Why? Because we weren’t just selling products; we were creating shopping journeys.\nYou still don’t believe me that the tree structure is powerful? Well let me give you a real-world example from the fashion industry. Stitch Fix, the online personal styling service, uses a sophisticated recommendation system that incorporates elements similar to our tree structure. According to their technology blog, they don’t just recommend individual items; they create entire outfits and style journeys for their customers. For instance, a customer might start with a basic pair of jeans. The system might then recommend a casual shirt (first level of the tree), followed by a jacket that complements both (second level), and finally accessories that pull the whole outfit together (third level). This creates a guided shopping experience that not only increases sales but also enhances customer satisfaction and loyalty. Their approach has been so successful that it’s become a core part of their business model, allowing them to compete effectively in the crowded fashion e-commerce space."
  },
  {
    "objectID": "posts/cold-start/index.html#the-secret-sauce-continuous-improvement",
    "href": "posts/cold-start/index.html#the-secret-sauce-continuous-improvement",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "The Secret Sauce: Continuous Improvement",
    "text": "The Secret Sauce: Continuous Improvement\nNow, here’s the part that separates the amateurs from the pros. Everything we’ve built so far? It’s just the beginning. The real magic happens when you start iterating.\n\nFine-tune your clustering: As you gather more data, you might realize that “price” isn’t as important as “style” in grouping brands. Don’t be afraid to adjust your features.\nAdjust association weights: Maybe being bought together in the same cart should be weighted more heavily than being bought by the same customer on different days. Experiment!\nPlay with tree depth: A deeper tree might create more interesting paths, but it might also lead to decision fatigue. Find the sweet spot for your customers.\nIncorporate user feedback: If a customer consistently ignores a certain brand in their recommendations, take the hint!\nA/B test everything: And I mean everything. Different clustering algorithms, different association models, different tree traversal methods. Let the data guide you.\n\nRemember, the goal isn’t to build a perfect system. The goal is to build a system that’s better than random chance, and then make it a little better every single day. How you ask? Well that’s the topic of another post…"
  },
  {
    "objectID": "posts/cold-start/index.html#the-plot-thickens-a-teaser-for-the-sequel",
    "href": "posts/cold-start/index.html#the-plot-thickens-a-teaser-for-the-sequel",
    "title": "The Surprisingly Lucrative Journey of Bootstrapping a Brand Recommender System: From Chaos to Cash",
    "section": "The Plot Thickens: A Teaser for the Sequel",
    "text": "The Plot Thickens: A Teaser for the Sequel\nNow, if you think we’ve reached the pinnacle of recommendation wizardry, hold onto your pocket protectors, folks. We’re about to dive deeper into the rabbit hole of personalization than Alice ever dreamed possible. In our next thrilling installment, we’ll be cooking up a recommendation system so bespoke, it’ll make Savile Row tailors jealish. We’re talking about harnessing the power of cutting-edge AI to create personalized purchase sequences that’ll make your customers feel like you’re reading their minds (in a totally non-creepy, GDPR-compliant way, of course).\nThink less “Customers who bought this also bought…” and more “Your next favorite purchase is just around the corner.” It’s like if your favorite personal shopper got bitten by a radioactive data scientist and developed super-powered prediction abilities. Intrigued? Excited? Contemplating a career change to data science? Stay tuned for Part 2, where we’ll turn your recommendation engine from a skilled matchmaker into a retail fortune teller. Don’t forget to bring your lucky algorithms!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shwetank Kumar",
    "section": "",
    "text": "I’m a physicist, engineering exec, investor. Here’s my story:\n\nBorn and raised in NCR, India. Delhi native, I live in SF.\nGot hooked on science early, did my B.Tech in EE from IIT, PhD in Applied Physics from Caltech.\nLearned business by working at startups for 10+ years and getting MBA at Wharton.\nI founded a bootstrapped company to help data teams optimize their Snowflake spend.\nI enjoy building stuff for internet and physical systems using data and AI games."
  },
  {
    "objectID": "index.html#personal-info-in-a-nutshell",
    "href": "index.html#personal-info-in-a-nutshell",
    "title": "Shwetank Kumar",
    "section": "",
    "text": "I’m a physicist, engineering exec, investor. Here’s my story:\n\nBorn and raised in NCR, India. Delhi native, I live in SF.\nGot hooked on science early, did my B.Tech in EE from IIT, PhD in Applied Physics from Caltech.\nLearned business by working at startups for 10+ years and getting MBA at Wharton.\nI founded a bootstrapped company to help data teams optimize their Snowflake spend.\nI enjoy building stuff for internet and physical systems using data and AI games."
  },
  {
    "objectID": "index.html#some-things-ive-done",
    "href": "index.html#some-things-ive-done",
    "title": "Shwetank Kumar",
    "section": "Some things I’ve done",
    "text": "Some things I’ve done\n\nBuilt AI systems that crunch petabytes of data across image, text, and tabular formats.\nScaled these systems to serve millions of customers simultaneously 1, 2.\nCreated systems that use neural networks to analyze satellite imagery at planet scale.\nLed teams of 120+ brilliant minds in data science, engineering, and analytics."
  },
  {
    "objectID": "index.html#tech-i-love-working-with",
    "href": "index.html#tech-i-love-working-with",
    "title": "Shwetank Kumar",
    "section": "Tech I love working with:",
    "text": "Tech I love working with:\n\nPyTorch, Hugging Face, Langchain, Pydantic\nGCP, Snowflake, Bigquery\nAnything that pushes the boundaries of what’s possible with data"
  },
  {
    "objectID": "index.html#investing",
    "href": "index.html#investing",
    "title": "Shwetank Kumar",
    "section": "Investing:",
    "text": "Investing:\n\nMy current areas of interest are: AI, infrastructure, open source, physical systems / frontier tech.\nSome companies I have invested in - Comet, Startree, Inference, Nimble, Turnstile, Dandelion…\nI am a founding member and part of the steering committee at Invest in Data where I co-invest with a group of ~50 other Data execs.\nWe vet and invest on a quarterly cadence. If you have an exciting AI project or a game-changing startup idea? Let’s talk: shwetank.kumar@gmail.com."
  },
  {
    "objectID": "index.html#where-you-can-find-me",
    "href": "index.html#where-you-can-find-me",
    "title": "Shwetank Kumar",
    "section": "Where you can find me:",
    "text": "Where you can find me:\n\nWriting about AI musings, tech & leadership, and data science on this blog\nSharing insights on LinkedIn\nTinkering with code on GitHub\nSpeaking on panels about the future of AI and data"
  }
]