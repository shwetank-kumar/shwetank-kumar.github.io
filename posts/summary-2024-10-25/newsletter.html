<!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>🌙 AI Afterhours: Top AI Papers for Oct 18 - Oct 24, 2024</title>
            <style>
                * { margin: 0; padding: 0; box-sizing: border-box; }
                body { 
                    font-family: 'Open Sans', Arial, sans-serif;
                    line-height: 1.6;
                    color: #2c3e50;
                    background-color: #f6f6f6;
                    padding: 20px;
                }
                .container {
                    max-width: 1200px;
                    margin: 0 auto;
                    background: white;
                    border-radius: 8px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    padding: 2rem;
                }
                .header {
                    text-align: center;
                    margin-bottom: 2rem;
                    background-color: #f6f6f6;
                    padding: 1.5rem;
                    border-radius: 8px;
                }
                .header h1 {
                    font-size: 2.5rem;
                    margin-bottom: 0.5rem;
                    color: #1a202c;
                }
                .header h2 {
                    font-size: 1.8rem;
                    color: #4a5568;
                    font-weight: 500;
                    margin-bottom: 1rem;
                }
                .content { 
                    max-width: 100%;
                    font-size: 1.1rem;
                    line-height: 1.8;
                }
                .content p {
                    margin-bottom: 1.5rem;
                    color: #2d3748;
                }
                .media-content {
                    background: #ffffff;
                    padding: 2rem;
                    border-radius: 8px;
                    margin: 2rem 0;
                    text-align: center;
                }
                .media-content h3 {
                    font-size: 1.5rem;
                    color: #1a202c;
                    margin-bottom: 1rem;
                }
                .media-content p {
                    font-size: 1.1rem;
                    color: #4a5568;
                    margin-bottom: 1.5rem;
                }
                .paper-summary {
                    background-color: #ffffff;
                    border-radius: 8px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                    margin-bottom: 2rem;
                    padding: 2rem;
                    transition: box-shadow 0.3s ease;
                }
                .paper-summary:hover { 
                    box-shadow: 0 4px 8px rgba(0,0,0,0.15); 
                }
                .paper-title {
                    font-size: 1.3rem;
                    line-height: 1.7;
                    color: #2d3748;
                    margin-bottom: 0.5rem;
                }
                .paper-title strong {
                    color: #1a202c;
                    font-size: 1.4rem;
                }
                .paper-footer {
                    display: flex;
                    justify-content: flex-end;
                    align-items: center;
                    margin-top: 1.5rem;
                    padding-top: 1rem;
                    border-top: 1px solid #e2e8f0;
                }
                .paper-metrics {
                    margin-left: 1rem;
                    font-size: 1rem;
                    color: #4a5568;
                }
                .newsletter-form {
                    background-color: #ffffff;
                    border-radius: 8px;
                    padding: 2.5rem;
                    text-align: center;
                    margin: 2rem 0;
                }
                .newsletter-form h4 {
                    color: #1a202c;
                    font-size: 1.6rem;
                    margin-bottom: 1rem;
                }
                .newsletter-form p {
                    font-size: 1.1rem;
                    color: #4a5568;
                    margin-bottom: 1.5rem;
                }
                .category {
                    color: #4a5568;
                    background-color: #edf2f7;
                    padding: 4px 12px;
                    margin: 4px;
                    border-radius: 6px;
                    font-size: 0.9rem;
                    display: inline-block;
                    font-weight: 500;
                }
                .read-more-section {
                    background-color: #f8fafc;
                    border-radius: 8px;
                    padding: 2.5rem;
                    margin-top: 2.5rem;
                    text-align: center;
                }
                .remaining-papers-header {
                    font-size: 1.8rem;
                    font-weight: bold;
                    color: #2b6cb0;
                    margin-bottom: 1.5rem;
                    line-height: 1.3;
                }
                .topics-list {
                    list-style: none;
                    padding: 0;
                    margin: 1.5rem 0;
                    text-align: left;
                    display: inline-block;
                }
                .topics-list li {
                    margin: 0.75rem 0;
                    padding-left: 1.5rem;
                    position: relative;
                    font-size: 1.1rem;
                    color: #2d3748;
                }
                .topics-list li:before {
                    content: "•";
                    position: absolute;
                    left: 0;
                    color: #2b6cb0;
                }
                .cta-button {
                    display: block;
                    background-color: #1a202c !important;
                    color: #ffffff !important;
                    padding: 14px 28px;
                    border-radius: 6px;
                    text-decoration: none;
                    margin: 2rem auto 0;
                    font-weight: 600;
                    font-size: 1.1rem;
                    transition: all 0.3s ease;
                    width: fit-content;
                }
                .cta-button:hover {
                    background-color: #2d3748 !important;
                    transform: translateY(-2px);
                }
                .paper-link {
                    text-decoration: none;
                    color: #2b6cb0;
                    font-weight: 600;
                    padding: 8px 20px;
                    border-radius: 6px;
                    transition: all 0.3s ease;
                    display: inline-block;
                    line-height: normal;
                    height: fit-content;
                    font-size: 1rem;
                }
                .paper-link:hover {
                    background-color: #ebf4ff;
                    transform: translateX(5px);
                }
                @media (max-width: 768px) {
                    .container { padding: 1rem; }
                    .paper-summary { padding: 1.5rem; }
                    .header h1 { font-size: 2rem; }
                    .header h2 { font-size: 1.5rem; }
                }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>🌙 AI Afterhours</h1>
                    <h2>Top AI Papers for Oct 18 - Oct 24, 2024</h2>
                    <div class="categories">
                        <span class="category">Video Object Segmentation</span>
<span class="category">Multi-Modal AI</span>
<span class="category">PyTorch</span>
<span class="category">Neural Radiance Fields</span>
<span class="category">Text-to-Video Synthesis</span>
<span class="category">Large Language Models</span>
<span class="category">Multi-Granular Visual Generation</span>
                    </div>
                </div>
                <div class="content">
                    <p>Welcome to this week's AI Afterhours! Your weekly digest of most upvoted papers in AI. Below is gist of the results, how they got them, and why you should care. With that, let's dive into the most exciting AI research from the past week.</p>
        <div class="media-content">
            <h3>🎧 Listen to This Week's Summary</h3>
            <p>Prefer to listen? Check out our audio summary:</p>
            <a href="https://podcasters.spotify.com/pod/show/shwetankkumar" class="cta-button">
                Listen on Spotify
            </a>
        </div>

        <div class="newsletter-form">
            <h4>Never Miss an AI Afterhours Research Update</h4>
            <p>Get weekly summaries delivered straight to your inbox</p>
            <a href="https://shwetank-kumar.github.io/blog.html" class="cta-button">
                Subscribe Now
            </a>
        </div>
                    <div class="paper-summary">
    <div class="paper-title"><strong>FrugalNeRF</strong> tackles one of the most pressing challenges in Neural Radiance Fields - the need for faster, more efficient scene reconstruction from limited viewpoints. By introducing a clever weight-sharing scheme across multiple voxel scales and a cross-scale geometric adaptation mechanism, the team achieved remarkable efficiency gains. The results speak for themselves: high-quality novel view synthesis in just 10 minutes on the LLFF dataset and 6 minutes on the DTU dataset, with superior PSNR, SSIM, and LPIPS scores compared to existing methods. This breakthrough could revolutionize applications from virtual reality to architectural visualization, where quick turnaround times from limited input data are crucial.</div>
    <div class="paper-footer">
        <a href="https://arxiv.org/pdf/2410.16271v1" class="paper-link" target="_blank">Read Full Paper</a>
        <span class="paper-metrics">👍 57 upvotes</span>
    </div>
</div>
<div class="paper-summary">
    <div class="paper-title"><strong>CompassJudger-1</strong> represents a significant step forward in how we evaluate large language models. This comprehensive judge model, trained on 900,000 entries of diverse data, achieves an impressive 95% accuracy rate on the JDB-B benchmark. What makes this particularly interesting is its optimal training data ratio discovery: 1:3:1 for critique data, reward data, and general SFT data respectively. The implications for AI development are substantial - we're moving towards more reliable, consistent evaluation methods that could accelerate the improvement cycle of language models.</div>
    <div class="paper-footer">
        <a href="https://arxiv.org/pdf/2410.16256v1" class="paper-link" target="_blank">Read Full Paper</a>
        <span class="paper-metrics">👍 51 upvotes</span>
    </div>
</div>
<div class="paper-summary">
    <div class="paper-title"><strong>Movie Gen</strong> is pushing the boundaries of media generation with an impressive suite of foundation models. The system shows remarkable capabilities in text-to-video synthesis and editing, backed by solid numbers: a 35.02% net win rate over previous work in overall quality and 48.49% in realness. With its largest model boasting 30B parameters and capable of generating 16-second videos at 16 fps, it's a significant leap forward. The implications for creative industries are enormous - from rapid prototyping in film production to democratizing video content creation.</div>
    <div class="paper-footer">
        <a href="https://arxiv.org/pdf/2410.13720v1" class="paper-link" target="_blank">Read Full Paper</a>
        <span class="paper-metrics">👍 50 upvotes</span>
    </div>
</div>

                <div class="read-more-section">
                    <h3 class="remaining-papers-header">+ 7 More Exciting Papers! 🎉</h3>
                    <ul class="topics-list">
                        <li>MixEval-X</li>
<li>SAM2Long</li>
<li>PUMA</li>
<li>SemiEvol</li>
<li>AutoTrain</li>
<li>UCFE</li>
<li>Baichuan Alignment</li>
                    </ul>
                    <div style="margin-top: 2rem;">
                        <a href="https://shwetank-kumar.github.io/blog.html" 
                        class="cta-button">
                            Read Full Research Summary
                        </a>
                    </div>
                </div>
                </div>
            </div>
        </body>
        </html>